{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQvY-qYdTv-x"
   },
   "source": [
    "# <center>Discriminative Regularize Generative Model for CIFAR10 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Rj9KcbOTv-z"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52422,
     "status": "ok",
     "timestamp": 1526728855320,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "XTv4faCZTv-0",
    "outputId": "527885ae-2da5-416c-c097-98ee6f293576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f54534a5050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip3 install --upgrade torch torchvision\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "#from google.colab import files\n",
    "\n",
    "#Set random seed \n",
    "torch.manual_seed(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "upjqkt52z27T"
   },
   "outputs": [],
   "source": [
    "class preTrainedModel(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "      \n",
    "      super(preTrainedModel,self).__init__()\n",
    "      \n",
    "      vgg_model = torchvision.models.vgg16(pretrained=True)\t\t\n",
    "      self.Conv1 = nn.Sequential(*list(vgg_model.features.children())[0:4])\n",
    "      #self.Conv2 = nn.Sequential(*list(vgg_model.features.children())[4:9]) \n",
    "      #self.Conv3 = nn.Sequential(*list(vgg_model.features.children())[9:16])\n",
    "      #self.upSample1 = nn.Upsample(scale_factor=2)\n",
    "      #self.upSample2 = nn.Upsample(scale_factor=4)\n",
    "\n",
    "    def forward(self,x):\n",
    "      out1 = self.Conv1(x)\n",
    "      #out2 = self.Conv2(out1)\n",
    "      #out3 = self.Conv3(out2)\n",
    "      ###### up sampling to create output with the same size\n",
    "      #out2 = self.upSample1(out2)\n",
    "      #out3 = self.upSample2(out3)\n",
    "      #concat_features = torch.cat([out1, out2, out3], 1)\n",
    "      return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 150022,
     "status": "ok",
     "timestamp": 1526729009116,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "SPpn7-HtTv_D",
    "outputId": "df1eb957-b421-45c9-d973-d4315385ae53"
   },
   "outputs": [],
   "source": [
    "#Load model \n",
    "vgg19 = preTrainedModel().eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22557,
     "status": "ok",
     "timestamp": 1526732111041,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "DsoOKn4BTv_F",
    "outputId": "9193b56f-8f76-4d96-cfeb-3a45d6d9174f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Get the CIFAR10 train images \n",
    "cifar = datasets.CIFAR10('./data/cifar/', train = True, download = True)\n",
    "\n",
    "# Organize training data in batches, \n",
    "# normalize them to have values between [-1, 1] (?)\n",
    "\n",
    "train_images = torch.utils.data.DataLoader ( datasets.CIFAR10('./data/cifar/', train = True, download=False,\n",
    "                               transform=transforms.Compose([\n",
    "                               #transforms.Resize(64), \n",
    "                               #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               transforms.ToTensor(),])) , \n",
    "                               batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1526732111666,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "0N6c7NtWTv_Z",
    "outputId": "7ae6d969-16df-4877-93ef-9a58cce95e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 256, 256])\n",
      "torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "upsampling = nn.Upsample(size=256)\n",
    "for batch_idx, (data,_) in enumerate(train_images):    \n",
    "    out = vgg19(upsampling(data.cuda()))\n",
    "    print(out.size())\n",
    "    print(data.size())\n",
    "    #print(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsFG7sSkTv_d"
   },
   "source": [
    "## Model\n",
    "\n",
    "We will use the arquitecture suggested by [Radford et al](https://arxiv.org/abs/1511.06434) for both the encoder and decoder. With convolutional layers in the encoder and fractionally-strided  convolutions  in  the  decoder.   In  each convolutional layer in the encoder we double the number of filters present in the previous layer and use a convolutional stride of 2.  In each convolutional layer in the decoder we use a fractional stride of 2 and halve the number of filters on each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BxB4_CTcTv_d"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class VAE( nn.Module ):\n",
    "\n",
    "    def __init__ ( self, image_size ,  hidden_dim , encoding_dim ):\n",
    "        \n",
    "        super( VAE, self ).__init__()\n",
    "        \n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.image_size = image_size\n",
    "        self.hidden_dim = hidden_dim \n",
    "        \n",
    "        # Decoder - Fractional strided convolutional layers\n",
    "        self.decoder  = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 1, 0, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1, bias = False),\n",
    "            nn.Sigmoid() # nn.Tanh()  \n",
    "        )\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, 2, 1, bias = False),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 0, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Fully-connected layers\n",
    "        self.fc1 = nn.Linear(256, self.hidden_dim)\n",
    "        self.fc21 = nn.Linear(self.hidden_dim, self.encoding_dim)\n",
    "        self.fc22 = nn.Linear(self.hidden_dim, self.encoding_dim)\n",
    "        self.fc3 = nn.Linear(self.encoding_dim, self.hidden_dim)\n",
    "        self.fc4 = nn.Linear(self.hidden_dim, 256)\n",
    "    \n",
    "    def decode (self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        h4 = F.sigmoid(self.fc4(h3))\n",
    "        return self.decoder( h4.view(z.size(0),-1,1,1) ) \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Encode \n",
    "        encoded = F.relu(self.fc1( self.encoder(x).view(x.size(0), -1) ) )\n",
    "        \n",
    "        #Obtain mu and logvar\n",
    "        mu = self.fc21( encoded )\n",
    "        logvar = self.fc22 ( encoded )\n",
    "        \n",
    "        #Reparametrization trick\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = eps.mul(std).add_(mu)\n",
    "        \n",
    "        # Decode \n",
    "        decoded = self.decode(z)\n",
    "\n",
    "        # return decoded, mu, logvar\n",
    "        return decoded, mu , logvar\n",
    "\n",
    "\n",
    "upsampling = nn.Upsample(size=256)\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    d1_recon_x = sigmoid(vgg19(upsampling( recon_x )))\n",
    "    d1_x = sigmoid(vgg19( upsampling( x )))\n",
    "\n",
    "    L1 = F.mse_loss(d1_recon_x, d1_x, size_average=False)\n",
    "    \n",
    "    del d1_recon_x \n",
    "    del d1_x\n",
    "    \n",
    "    return BCE + KLD + L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72496,
     "status": "ok",
     "timestamp": 1526733558939,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "Xa14nLhnTv_f",
    "outputId": "fb6d3fa2-34a5-4f4b-dc74-06b644aa0504"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "#Define model\n",
    "model = VAE( 32, 100, 20 ).cuda()\n",
    "model.load_state_dict(torch.load('../models_save_cifar_checkpoint_epoch_100_bs32.pth'))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#Train model\n",
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_images):\n",
    "        data = Variable(data).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_images.dataset),\n",
    "                100. * batch_idx / len(train_images),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_images.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1706493,
     "status": "ok",
     "timestamp": 1526735322524,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "GJFbZKvNTv_h",
    "outputId": "f3152711-6b27-4c1f-8255-1c89aec2d371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 7190.321289\n",
      "Train Epoch: 100 [1600/50000 (3%)]\tLoss: 7238.188477\n",
      "Train Epoch: 100 [3200/50000 (6%)]\tLoss: 8057.375000\n",
      "Train Epoch: 100 [4800/50000 (10%)]\tLoss: 7924.512207\n",
      "Train Epoch: 100 [6400/50000 (13%)]\tLoss: 7249.840332\n",
      "Train Epoch: 100 [8000/50000 (16%)]\tLoss: 7964.744141\n",
      "Train Epoch: 100 [9600/50000 (19%)]\tLoss: 7319.520508\n",
      "Train Epoch: 100 [11200/50000 (22%)]\tLoss: 7112.331055\n",
      "Train Epoch: 100 [12800/50000 (26%)]\tLoss: 7724.154785\n",
      "Train Epoch: 100 [14400/50000 (29%)]\tLoss: 7325.783203\n",
      "Train Epoch: 100 [16000/50000 (32%)]\tLoss: 7527.185547\n",
      "Train Epoch: 100 [17600/50000 (35%)]\tLoss: 7391.567383\n",
      "Train Epoch: 100 [19200/50000 (38%)]\tLoss: 7370.445801\n",
      "Train Epoch: 100 [20800/50000 (42%)]\tLoss: 7147.286133\n",
      "Train Epoch: 100 [22400/50000 (45%)]\tLoss: 7449.463379\n",
      "Train Epoch: 100 [24000/50000 (48%)]\tLoss: 7183.831055\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLoss: 7055.037109\n",
      "Train Epoch: 100 [27200/50000 (54%)]\tLoss: 7351.858398\n",
      "Train Epoch: 100 [28800/50000 (58%)]\tLoss: 7301.176758\n",
      "Train Epoch: 100 [30400/50000 (61%)]\tLoss: 7436.866211\n",
      "Train Epoch: 100 [32000/50000 (64%)]\tLoss: 7513.942383\n",
      "Train Epoch: 100 [33600/50000 (67%)]\tLoss: 8413.203125\n",
      "Train Epoch: 100 [35200/50000 (70%)]\tLoss: 7568.721191\n",
      "Train Epoch: 100 [36800/50000 (74%)]\tLoss: 7793.541016\n",
      "Train Epoch: 100 [38400/50000 (77%)]\tLoss: 7253.674805\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 9052.655273\n",
      "Train Epoch: 100 [41600/50000 (83%)]\tLoss: 7328.030273\n",
      "Train Epoch: 100 [43200/50000 (86%)]\tLoss: 7415.531738\n",
      "Train Epoch: 100 [44800/50000 (90%)]\tLoss: 8159.709473\n",
      "Train Epoch: 100 [46400/50000 (93%)]\tLoss: 7460.569336\n",
      "Train Epoch: 100 [48000/50000 (96%)]\tLoss: 7428.944336\n",
      "Train Epoch: 100 [49600/50000 (99%)]\tLoss: 7288.818848\n",
      "====> Epoch: 100 Average loss: 7480.5012\n",
      "Time elapsed: 316.49\n",
      "Train Epoch: 101 [0/50000 (0%)]\tLoss: 7793.735352\n",
      "Train Epoch: 101 [1600/50000 (3%)]\tLoss: 7602.335449\n",
      "Train Epoch: 101 [3200/50000 (6%)]\tLoss: 7372.224609\n",
      "Train Epoch: 101 [4800/50000 (10%)]\tLoss: 7653.450684\n",
      "Train Epoch: 101 [6400/50000 (13%)]\tLoss: 7206.279297\n",
      "Train Epoch: 101 [8000/50000 (16%)]\tLoss: 7090.636719\n",
      "Train Epoch: 101 [9600/50000 (19%)]\tLoss: 7719.401367\n",
      "Train Epoch: 101 [11200/50000 (22%)]\tLoss: 7684.136719\n",
      "Train Epoch: 101 [12800/50000 (26%)]\tLoss: 7258.023438\n",
      "Train Epoch: 101 [14400/50000 (29%)]\tLoss: 7265.935547\n",
      "Train Epoch: 101 [16000/50000 (32%)]\tLoss: 7741.304199\n",
      "Train Epoch: 101 [17600/50000 (35%)]\tLoss: 7594.485352\n",
      "Train Epoch: 101 [19200/50000 (38%)]\tLoss: 7527.611328\n",
      "Train Epoch: 101 [20800/50000 (42%)]\tLoss: 6996.519531\n",
      "Train Epoch: 101 [22400/50000 (45%)]\tLoss: 7447.099121\n",
      "Train Epoch: 101 [24000/50000 (48%)]\tLoss: 7593.722656\n",
      "Train Epoch: 101 [25600/50000 (51%)]\tLoss: 6902.015137\n",
      "Train Epoch: 101 [27200/50000 (54%)]\tLoss: 7772.741211\n",
      "Train Epoch: 101 [28800/50000 (58%)]\tLoss: 7243.958008\n",
      "Train Epoch: 101 [30400/50000 (61%)]\tLoss: 7658.994629\n",
      "Train Epoch: 101 [32000/50000 (64%)]\tLoss: 7812.389648\n",
      "Train Epoch: 101 [33600/50000 (67%)]\tLoss: 7524.164062\n",
      "Train Epoch: 101 [35200/50000 (70%)]\tLoss: 7174.941406\n",
      "Train Epoch: 101 [36800/50000 (74%)]\tLoss: 7053.394531\n",
      "Train Epoch: 101 [38400/50000 (77%)]\tLoss: 7417.445312\n",
      "Train Epoch: 101 [40000/50000 (80%)]\tLoss: 7201.749023\n",
      "Train Epoch: 101 [41600/50000 (83%)]\tLoss: 7929.122070\n",
      "Train Epoch: 101 [43200/50000 (86%)]\tLoss: 7033.873047\n",
      "Train Epoch: 101 [44800/50000 (90%)]\tLoss: 7717.301758\n",
      "Train Epoch: 101 [46400/50000 (93%)]\tLoss: 7803.605957\n",
      "Train Epoch: 101 [48000/50000 (96%)]\tLoss: 6965.526367\n",
      "Train Epoch: 101 [49600/50000 (99%)]\tLoss: 6751.821289\n",
      "====> Epoch: 101 Average loss: 7476.4171\n",
      "Time elapsed: 320.55\n",
      "Train Epoch: 102 [0/50000 (0%)]\tLoss: 6896.816406\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(100,num_epochs+1):\n",
    "    start = time.time()\n",
    "    train(epoch)    \n",
    "    end = time.time()\n",
    "    print(f'Time elapsed: {end - start:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WYzZZVPjTv_u"
   },
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), \"../models_save_cifar_checkpoint_epoch_200_bs32.pth\")\n",
    "# files.download(\"save_checkpoint_epoch_70.pth\")\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 795
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598,
     "status": "error",
     "timestamp": 1526735730327,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "4lxOTzHYQKGu",
    "outputId": "e71752c5-4e9b-403f-e72c-0dc58a1c6ca3"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        sample = torch.randn(64, 20)\n",
    "        sample = model.decode(sample)\n",
    "        #torch.save(model.cpu().state_dict(), \"./save_checkpoint_epoch_\"+str(epoch)+\".pth\")\n",
    "        #files.download(\"./save_checkpoint_epoch_\"+str(epoch)+\".pth\")\n",
    "        torchvision.utils.save_image(sample.view(64, 3, 32, 32),'../results/sample_cifar_' + str(epoch) + '_bs32.png')\n",
    "#         files.download('./sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qvQl9CwvYNRb"
   },
   "outputs": [],
   "source": [
    "torch.save(sample.cpu(), \"sample_70.pth\")\n",
    "files.download(\"sample_70.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1526652682691,
     "user": {
      "displayName": "Alfredo Alejandro De la Fuente Briceño",
      "photoUrl": "//lh3.googleusercontent.com/-KuSUlXYxUa0/AAAAAAAAAAI/AAAAAAAAACI/FWR29NQO7b8/s50-c-k-no/photo.jpg",
      "userId": "115022533346902252990"
     },
     "user_tz": -180
    },
    "id": "nU4DWrDXaMtT",
    "outputId": "ebde9c9b-54d1-4f19-d3fc-aeba3999c08e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "COzRhVNGYUu6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "DisRegGen-CIFAR10_Final.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
